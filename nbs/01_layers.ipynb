{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Layers\" data-toc-modified-id=\"Layers-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Layers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Patches\" data-toc-modified-id=\"Patches-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Patches</a></span><ul class=\"toc-item\"><li><span><a href=\"#RoIHeads\" data-toc-modified-id=\"RoIHeads-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>RoIHeads</a></span></li><li><span><a href=\"#GeneralizedRCNN\" data-toc-modified-id=\"GeneralizedRCNN-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>GeneralizedRCNN</a></span></li></ul></li></ul></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from mantisshrimp.imports import *\n",
    "from mantisshrimp.core import *\n",
    "from torchvision.models.detection.roi_heads import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "> Definitions and patches of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoIHeads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "@patch\n",
    "def forward(self:RoIHeads,\n",
    "            features,      # type: Dict[str, Tensor]\n",
    "            proposals,     # type: List[Tensor]\n",
    "            image_shapes,  # type: List[Tuple[int, int]]\n",
    "            targets=None   # type: Optional[List[Dict[str, Tensor]]]\n",
    "            ):\n",
    "    # type: (...) -> Tuple[List[Dict[str, Tensor]], Dict[str, Tensor]]\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        features (List[Tensor])\n",
    "        proposals (List[Tensor[N, 4]])\n",
    "        image_shapes (List[Tuple[H, W]])\n",
    "        targets (List[Dict])\n",
    "    \"\"\"\n",
    "    if targets is not None:\n",
    "        for t in targets:\n",
    "            # TODO: https://github.com/pytorch/pytorch/issues/26731\n",
    "            floating_point_types = (torch.float, torch.double, torch.half)\n",
    "            assert t[\"boxes\"].dtype in floating_point_types, 'target boxes must of float type'\n",
    "            assert t[\"labels\"].dtype == torch.int64, 'target labels must of int64 type'\n",
    "            if self.has_keypoint():\n",
    "                assert t[\"keypoints\"].dtype == torch.float32, 'target keypoints must of float type'\n",
    "\n",
    "    if not self.training:\n",
    "        labels = None\n",
    "        regression_targets = None\n",
    "        matched_idxs = None\n",
    "    if targets is not None:\n",
    "        proposals, matched_idxs, labels, regression_targets = self.select_training_samples(proposals, targets)\n",
    "\n",
    "    box_features = self.box_roi_pool(features, proposals, image_shapes)\n",
    "    box_features = self.box_head(box_features)\n",
    "    class_logits, box_regression = self.box_predictor(box_features)\n",
    "\n",
    "    result = torch.jit.annotate(List[Dict[str, torch.Tensor]], [])\n",
    "    losses = {}\n",
    "    if targets is not None:\n",
    "        assert labels is not None and regression_targets is not None\n",
    "        loss_classifier, loss_box_reg = fastrcnn_loss(\n",
    "            class_logits, box_regression, labels, regression_targets)\n",
    "        losses = {\n",
    "            \"loss_classifier\": loss_classifier,\n",
    "            \"loss_box_reg\": loss_box_reg\n",
    "        }\n",
    "    if not self.training:\n",
    "        boxes, scores, labels = self.postprocess_detections(class_logits, box_regression, proposals, image_shapes)\n",
    "        num_images = len(boxes)\n",
    "        for i in range(num_images):\n",
    "            result.append(\n",
    "                {\n",
    "                    \"boxes\": boxes[i],\n",
    "                    \"labels\": labels[i],\n",
    "                    \"scores\": scores[i],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    if self.has_mask():\n",
    "        mask_proposals = [p[\"boxes\"] for p in result]\n",
    "        if not self.training:\n",
    "            pos_matched_idxs = None\n",
    "        if targets is not None:\n",
    "            assert matched_idxs is not None\n",
    "            # during training, only focus on positive boxes\n",
    "            num_images = len(proposals)\n",
    "            mask_proposals = []\n",
    "            pos_matched_idxs = []\n",
    "            for img_id in range(num_images):\n",
    "                pos = torch.nonzero(labels[img_id] > 0).squeeze(1)\n",
    "                mask_proposals.append(proposals[img_id][pos])\n",
    "                pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "\n",
    "        if self.mask_roi_pool is not None:\n",
    "            mask_features = self.mask_roi_pool(features, mask_proposals, image_shapes)\n",
    "            mask_features = self.mask_head(mask_features)\n",
    "            mask_logits = self.mask_predictor(mask_features)\n",
    "        else:\n",
    "            mask_logits = torch.tensor(0)\n",
    "            raise Exception(\"Expected mask_roi_pool to be not None\")\n",
    "\n",
    "        loss_mask = {}\n",
    "        if targets is not None:\n",
    "            assert targets is not None\n",
    "            assert pos_matched_idxs is not None\n",
    "            assert mask_logits is not None\n",
    "\n",
    "            gt_masks = [t[\"masks\"] for t in targets]\n",
    "            gt_labels = [t[\"labels\"] for t in targets]\n",
    "            rcnn_loss_mask = maskrcnn_loss(\n",
    "                mask_logits, mask_proposals,\n",
    "                gt_masks, gt_labels, pos_matched_idxs)\n",
    "            loss_mask = {\n",
    "                \"loss_mask\": rcnn_loss_mask\n",
    "            }\n",
    "        if not self.training:\n",
    "            labels = [r[\"labels\"] for r in result]\n",
    "            masks_probs = maskrcnn_inference(mask_logits, labels)\n",
    "            for mask_prob, r in zip(masks_probs, result):\n",
    "                r[\"masks\"] = mask_prob\n",
    "\n",
    "        losses.update(loss_mask)\n",
    "\n",
    "    # keep none checks in if conditional so torchscript will conditionally\n",
    "    # compile each branch\n",
    "    if self.keypoint_roi_pool is not None and self.keypoint_head is not None \\\n",
    "            and self.keypoint_predictor is not None:\n",
    "        keypoint_proposals = [p[\"boxes\"] for p in result]\n",
    "        if not self.training:\n",
    "            pos_matched_idxs = None\n",
    "        if targets is not None:\n",
    "            # during training, only focus on positive boxes\n",
    "            num_images = len(proposals)\n",
    "            keypoint_proposals = []\n",
    "            pos_matched_idxs = []\n",
    "            assert matched_idxs is not None\n",
    "            for img_id in range(num_images):\n",
    "                pos = torch.nonzero(labels[img_id] > 0).squeeze(1)\n",
    "                keypoint_proposals.append(proposals[img_id][pos])\n",
    "                pos_matched_idxs.append(matched_idxs[img_id][pos])\n",
    "\n",
    "        keypoint_features = self.keypoint_roi_pool(features, keypoint_proposals, image_shapes)\n",
    "        keypoint_features = self.keypoint_head(keypoint_features)\n",
    "        keypoint_logits = self.keypoint_predictor(keypoint_features)\n",
    "\n",
    "        loss_keypoint = {}\n",
    "        if targets is not None:\n",
    "            assert targets is not None\n",
    "            assert pos_matched_idxs is not None\n",
    "\n",
    "            gt_keypoints = [t[\"keypoints\"] for t in targets]\n",
    "            rcnn_loss_keypoint = keypointrcnn_loss(\n",
    "                keypoint_logits, keypoint_proposals,\n",
    "                gt_keypoints, pos_matched_idxs)\n",
    "            loss_keypoint = {\n",
    "                \"loss_keypoint\": rcnn_loss_keypoint\n",
    "            }\n",
    "        if not self.training:\n",
    "            assert keypoint_logits is not None\n",
    "            assert keypoint_proposals is not None\n",
    "\n",
    "            keypoints_probs, kp_scores = keypointrcnn_inference(keypoint_logits, keypoint_proposals)\n",
    "            for keypoint_prob, kps, r in zip(keypoints_probs, kp_scores, result):\n",
    "                r[\"keypoints\"] = keypoint_prob\n",
    "                r[\"keypoints_scores\"] = kps\n",
    "\n",
    "        losses.update(loss_keypoint)\n",
    "\n",
    "    return result, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeneralizedRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "@torch.jit.unused\n",
    "@patch\n",
    "def eager_outputs(self:GeneralizedRCNN, losses, detections):\n",
    "    # type: (Dict[str, Tensor], List[Dict[str, Tensor]]) -> Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]\n",
    "    if losses and detections: return (losses, detections)\n",
    "    if losses: return losses\n",
    "    if detections: return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.core.ipynb.\n",
      "Converted 04_data.annotations.ipynb.\n",
      "Converted 06_data.load.ipynb.\n",
      "Converted 07_transforms.ipynb.\n",
      "Converted 08_models.ipynb.\n",
      "Converted 11_metrics.core.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted Untitled1.ipynb.\n",
      "Converted data_refactor.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
