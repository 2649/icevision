{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from collections import UserList\n",
    "from copy import deepcopy\n",
    "from dataclasses import replace\n",
    "from mantisshrimp.imports import *\n",
    "from mantisshrimp.core import *\n",
    "from mantisshrimp.data.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data annotation\n",
    "> Functions for getting annotatations in a standard format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Mask:\n",
    "    data: np.ndarray\n",
    "    def __post_init__(self): self.data = self.data.astype(np.uint8)\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self, i): return type(self)(self.data[i])\n",
    "    \n",
    "    def to_tensor(self): return tensor(self.data, dtype=torch.uint8)\n",
    "    def to_mask(self, h, w): return self\n",
    "    @property\n",
    "    def shape(self): return self.data.shape\n",
    "    \n",
    "    @classmethod\n",
    "    def from_segs(cls, segs, h, w):\n",
    "        masks = []\n",
    "        # TODO: Instead of if checks, RLE and Polygon can return with extra dim\n",
    "        for o in segs:\n",
    "            m = o.to_mask(h,w).data\n",
    "            if isinstance(o, (RLE, Polygon)): masks.append(m[None])\n",
    "            elif isinstance(o, MaskFile): masks.append(m)\n",
    "            else: raise ValueError(f'Segmented type {type(o)} not supported')\n",
    "        return cls(np.concatenate([o.to_mask(h, w).data for o in segs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class MaskFile:\n",
    "    fp: Union[str, Path]\n",
    "    def __post_init__(self): self.fp = Path(self.fp)\n",
    "    def to_mask(self, h, w):\n",
    "        mask = open_img(self.fp, gray=True)\n",
    "        obj_ids = np.unique(mask)[1:]\n",
    "        masks = mask==obj_ids[:, None, None]\n",
    "        return Mask(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class RLE:\n",
    "    counts: List[int]\n",
    "    def to_mask(self, h, w):\n",
    "        erle = mask_utils.frPyObjects([{'counts':self.counts, 'size':[h,w]}], h, w)\n",
    "        mask = mask_utils.decode(erle).sum(axis=-1) # Sum is for unconnected polygons\n",
    "        assert mask.max() == 1, 'Probable overlap in polygons'\n",
    "        return Mask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Polygon:\n",
    "    pnts: List[List[int]]\n",
    "    def to_mask(self, h, w): \n",
    "        erle = mask_utils.frPyObjects(self.pnts, h, w)\n",
    "        mask = mask_utils.decode(erle).sum(axis=-1) # Sum is for unconnected polygons\n",
    "        assert mask.max() == 1, 'Probable overlap in polygons'\n",
    "        return Mask(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class BBox:\n",
    "    pnts: List[int]\n",
    "    def __post_init__(self):\n",
    "        if self.pnts:\n",
    "            xl,yu,xr,yb = self.pnts\n",
    "            self.x,self.y,self.h,self.w = xl,yu,(yb-yu),(xr-xl)\n",
    "            self.area = self.h*self.w\n",
    "    @property\n",
    "    def xyxy(self): return self.pnts\n",
    "    @property\n",
    "    def xywh(self): return [self.x,self.y,self.w,self.h]\n",
    "    @classmethod\n",
    "    def from_xywh(cls, x, y, w, h): return cls([x,y,x+w,y+h])\n",
    "    @classmethod\n",
    "    def from_xyxy(cls, xl, yu, xr, yb): return cls([xl,yu,xr,yb])\n",
    "    \n",
    "    def to_tensor(self): return tensor(self.xyxy, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class ImageInfo:\n",
    "    # TODO: Can add width and height\n",
    "    iid: int\n",
    "    fp: Union[str, Path]\n",
    "    split: int\n",
    "    h: int\n",
    "    w: int\n",
    "        \n",
    "    def __post_init__(self): self.fp = Path(self.fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Instance:\n",
    "    oid: int\n",
    "    bbox: BBox=None\n",
    "    seg: Polygon=None\n",
    "    kpts: List=None # TODO\n",
    "    iscrowd: int=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: Better way to handle empty oids, bboxes, kpts, segs etcs\n",
    "@dataclass\n",
    "class Annotation:\n",
    "    iid: int\n",
    "    oids: List[int]\n",
    "    bboxes: List[BBox]=None\n",
    "    segs: List[Polygon]=None\n",
    "    kpts: List[int]=None # TODO\n",
    "    iscrowds: List[int]=None\n",
    "        \n",
    "#     def __post_init__(self):\n",
    "#         insts = [self.oids,self.bboxes,self.segs,self.kpts,self.iscrowds]\n",
    "#         lens = [len(o) for o in insts if notnone(o)]\n",
    "#         if not allequal(lens): raise ValueError(f'All annotations should have the same size: {lens}')\n",
    "#         assert len(self.bboxes)==len(self.segs)\n",
    "    def __getitem__(self, i):\n",
    "        # TODO: Needs to be refactored?\n",
    "        bbox = self.bboxes[i] if notnone(self.bboxes) else None\n",
    "        seg = self.segs[i] if (notnone(self.segs) and len(self.segs)>i) else None # Single mask file can contain multiple masks\n",
    "        kpts = self.kpts[i] if notnone(self.kpts) else None\n",
    "        iscrowd = self.iscrowds[i] if notnone(self.iscrowds) else None\n",
    "        return Instance(oid=self.oids[i],bbox=bbox,seg=seg,kpts=None,iscrowd=iscrowd) #kpts None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Record:\n",
    "    iinfo: ImageInfo\n",
    "    annot: Annotation\n",
    "        \n",
    "    def new(self, *, iinfo=None, annot=None):\n",
    "        iinfo = replace(self.iinfo, **(iinfo or {}))\n",
    "        annot = replace(self.annot, **(annot or {}))\n",
    "        return replace(self, iinfo=iinfo, annot=annot)\n",
    "    \n",
    "    def to_rcnn_target(self):\n",
    "        r = {\n",
    "            'image_id': tensor(self.iinfo.iid, dtype=torch.int64),\n",
    "            'labels': tensor(self.annot.oids),\n",
    "            'boxes': torch.stack([o.to_tensor() for o in self.annot.bboxes]),\n",
    "        #     'keypoints': self.annot.kpts.to_tensor(), # TODO\n",
    "            'area': tensor([o.area for o in self.annot.bboxes]),\n",
    "            'iscrowd': tensor(self.annot.iscrowds, dtype=torch.uint8),\n",
    "        }\n",
    "        segs = self.annot.segs\n",
    "        if notnone(segs):\n",
    "            if isinstance(segs, Mask): m = segs\n",
    "            elif isinstance(segs, list): m = Mask.from_segs(segs, self.iinfo.h, self.iinfo.w)\n",
    "            else: raise ValueError(f'Type for masks {type(masks)} not supported')\n",
    "            r['masks'] = m.to_tensor()\n",
    "        # TODO: Check all shapes have N\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataSplit:\n",
    "    Train = 0\n",
    "    Valid = 1\n",
    "    Test = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_split(p=None, splits=None):\n",
    "    p = p or [.8, .2]\n",
    "    splits = splits or [DataSplit.Train, DataSplit.Valid, DataSplit.Test][:len(p)]\n",
    "    return np.random.choice(splits, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageParser:\n",
    "    def __init__(self, data, source): self.data,self.source = data,Path(source)\n",
    "    def __iter__(self): yield from self.data\n",
    "    def __len__(self): return len(self.data)\n",
    "        \n",
    "    def prepare(self, o): pass\n",
    "    def iid(self, o): raise NotImplementedError\n",
    "    def file_path(self, o): raise NotImplementedError\n",
    "    def height(self, o): raise NotImplementedError\n",
    "    def width(self, o): raise NotImplementedError\n",
    "    def split(self, o): return random_split()\n",
    "        \n",
    "    def parse(self):\n",
    "        xs,iids = [],[]\n",
    "        for o in tqdm(self):\n",
    "            self.prepare(o)\n",
    "            iid = self.iid(o)\n",
    "            if iid not in iids:\n",
    "                iids.append(iid)\n",
    "                xs.append(ImageInfo(iid=self.iid(o), fp=self.file_path(o), split=self.split(o),\n",
    "                                    h=self.height(o), w=self.width(o)))\n",
    "        return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AnnotationParser:\n",
    "    def __init__(self, data, source): self.data,self.source = data,source\n",
    "    def __iter__(self): yield from self.data\n",
    "    def __len__(self): return len(self.data)\n",
    "    # Methods to override\n",
    "    def prepare(self, o): pass\n",
    "    def bbox(self, o): pass\n",
    "    def iid(self, o): pass\n",
    "    def seg(self, o): pass\n",
    "    def iscrowd(self, o): return 0\n",
    "    \n",
    "    # TODO: Refactor\n",
    "    def parse(self):\n",
    "        res = defaultdict(dict)\n",
    "        iids = set()\n",
    "        bboxes = defaultdict(list)\n",
    "        segs = defaultdict(list)\n",
    "        oids = defaultdict(list)\n",
    "        iscrowds = defaultdict(list)\n",
    "        for o in tqdm(self):\n",
    "            self.prepare(o)\n",
    "            iid = self.iid(o)\n",
    "            bbox = self.bbox(o)\n",
    "            seg = self.seg(o)\n",
    "            oid = self.oid(o)\n",
    "            iscrowd = self.iscrowd(o)\n",
    "            if oid is not None: oids[iid].extend(L(oid))\n",
    "            if bbox is not None: bboxes[iid].extend(L(bbox))\n",
    "            if seg is not None: segs[iid].extend(L(seg))\n",
    "            if iscrowd is not None: iscrowds[iid].extend(L(iscrowd))\n",
    "            iids.add(iid)\n",
    "        for d in [bboxes,segs,oids,iscrowds]: d.default_factory = lambda: None\n",
    "        return [Annotation(i, oids[i], bboxes=bboxes[i], segs=segs[i], iscrowds=iscrowds[i]) for i in iids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataParser:\n",
    "    def __init__(self, data, source): self.data,self.source=data,source\n",
    "    def get_img_parser(self, o, source): raise NotImplementedError\n",
    "    def get_annot_parser(self, o, source): raise NotImpletedError\n",
    "        \n",
    "    def parse(self):\n",
    "        imgs = L(self.get_img_parser(self.data, self.source).parse())\n",
    "        annots = L(self.get_annot_parser(self.data, self.source).parse())\n",
    "        # Remove imgs that don't have annotations\n",
    "        img_iids = set(imgs.attrgot('iid'))\n",
    "        valid_iids = set(annots.attrgot('iid'))\n",
    "        if not valid_iids.issubset(img_iids):\n",
    "            raise ValueError(f'iids {valid_iids-img_iids} present in annotations but not in images')\n",
    "        valid_imgs = imgs.filter(lambda o: o.iid in valid_iids)\n",
    "        print(f\"Removed {len(imgs)-len(valid_iids)} images that don't have annotations\")\n",
    "        # Sort and get items\n",
    "        assert len(annots)==len(valid_imgs)\n",
    "        valid_imgs.sort(attrgetter('iid'))\n",
    "        annots.sort(attrgetter('iid'))\n",
    "        records = defaultdict(list)\n",
    "        for iinfo,annot in zip(valid_imgs,annots):\n",
    "            records[iinfo.split].append(Record(iinfo,annot))\n",
    "        return [records[k] for k in records.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class COCOImageParser(ImageParser):\n",
    "    def iid(self, o): return o['id']\n",
    "    def file_path(self, o): return self.source/o['file_name']\n",
    "    def height(self, o): return o['height']\n",
    "    def width(self, o): return o['width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class COCOAnnotationParser(AnnotationParser):\n",
    "    def iid(self, o):  return o['image_id']\n",
    "    def oid(self, o): return o['category_id']\n",
    "    def bbox(self, o): return BBox.from_xywh(*o['bbox'])\n",
    "    def iscrowd(self, o): return o['iscrowd']\n",
    "    def seg(self, o):\n",
    "        seg = o['segmentation']\n",
    "        if o['iscrowd']: return RLE(seg['counts'])\n",
    "        else: return Polygon(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class COCOParser(DataParser):\n",
    "    def get_img_parser(self, o, source): return COCOImageParser(o['images'], source)\n",
    "    def get_annot_parser(self, o, source): return COCOAnnotationParser(o['annotations'], source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = Path('samples')\n",
    "annot_json = json.load((source/'annotations.json').open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = COCOParser(annot_json, 'samples/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6354885a1e6b47adb4e7c69b7aa6e3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d26416288504a2db8bea16947ca0772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=36.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removed 0 images that don't have annotations\n"
     ]
    }
   ],
   "source": [
    "rtrain,rvalid = parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(rtrain)+len(rvalid), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Splits are random, tests fail\n",
    "r = records[0]\n",
    "test_eq((r.iinfo.h, r.iinfo.w), (427, 640))\n",
    "test_eq(r.iinfo.iid, 128372)\n",
    "test_eq(r.annot[0].bbox.xywh, [0.0, 73.89, 416.44, 305.13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.annot.segs[0].to_mask(r.iinfo.h, r.iinfo.w).data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = r.new(annot=dict(bboxes=[BBox.from_xyxy(1,2,3,4) for _ in r.annot.bboxes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ne(new.annot.bboxes, r.annot.bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.to_rcnn_target()['masks'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from matplotlib import patches\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_record(record, im=None, id2cat=None, bbox=False, fontsize=18, ax=None, **kwargs):\n",
    "    'From github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py#L233'\n",
    "    im = im if notnone(im) else open_img(record.iinfo.fp)\n",
    "    height,width,_ = im.shape\n",
    "    ax = show_img(im, ax=ax, **kwargs)\n",
    "    ax.set_autoscale_on(False)\n",
    "    polygons = []\n",
    "    color = []\n",
    "    for ann in record.annot:\n",
    "        c = (np.random.random((1, 3))*0.6+0.4).tolist()[0]\n",
    "        # Assert both seg and masks are not present, or unify view\n",
    "        if ann.seg is not None:\n",
    "            if isinstance(ann.seg, Polygon):\n",
    "                for seg in ann.seg.pnts:\n",
    "                    poly = np.array(seg).reshape((int(len(seg)/2), 2))\n",
    "                    polygons.append(patches.Polygon(poly))\n",
    "                    color.append(c)\n",
    "            elif isinstance(ann.seg, RLE):\n",
    "                if isinstance(ann.seg.counts, list):\n",
    "#                     rle = mask_utils.frPyObjects([ann.seg.counts], height, width)\n",
    "                    m = ann.seg.to_mask(height, width).data\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "    #                 rle = [ann['segmentation']]\n",
    "#                 m = mask_utils.decode(rle)\n",
    "                if ann.iscrowd == 1: color_mask = np.array([2.0,166.0,101.0])/255\n",
    "                if ann.iscrowd == 0: raise NotImplementedError # TODO: I'm not sure how to handle this case\n",
    "    #                 color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "            elif isinstance(ann.seg, MaskFile):\n",
    "                masks = ann.seg.to_mask(height, width).data\n",
    "                color_masks = np.random.random((masks.shape[0], 3))\n",
    "                imgs = np.ones((*masks.shape, 3))\n",
    "                for img,m,color_mask in zip(imgs,masks,color_masks):\n",
    "                    for i in range(3):\n",
    "                        img[:,:,i] = color_mask[i]\n",
    "                    ax.imshow(np.dstack((img, m*0.5)))\n",
    "            elif isinstance(ann.seg, Mask):\n",
    "                m = ann.seg.data\n",
    "                color_mask = np.random.random(3)\n",
    "            else: raise ValueError(f'Not supported type: {type(ann.seg)}')\n",
    "            if isinstance(ann.seg, RLE) or isinstance(ann.seg, Mask):\n",
    "                img = np.ones( (m.shape[0], m.shape[1], 3) )\n",
    "                for i in range(3):\n",
    "                    img[:,:,i] = color_mask[i]\n",
    "                ax.imshow(np.dstack( (img, m*0.5) ))\n",
    "        if ann.kpts and type(ann['keypoints']) == list:\n",
    "            raise NotImplementedError\n",
    "            # turn skeleton into zero-based index\n",
    "    #                     sks = np.array(self.loadCats(ann['category_id'])[0]['skeleton'])-1\n",
    "    #                     kp = np.array(ann['keypoints'])\n",
    "    #                     x = kp[0::3]\n",
    "    #                     y = kp[1::3]\n",
    "    #                     v = kp[2::3]\n",
    "    #                     for sk in sks:\n",
    "    #                         if np.all(v[sk]>0):\n",
    "    #                             plt.plot(x[sk],y[sk], linewidth=3, color=c)\n",
    "    #                     ax.plot(x[v>0], y[v>0],'o',markersize=8, markerfacecolor=c, markeredgecolor='k',markeredgewidth=2)\n",
    "    #                     ax.plot(x[v>1], y[v>1],'o',markersize=8, markerfacecolor=c, markeredgecolor=c, markeredgewidth=2)\n",
    "\n",
    "        if bbox:\n",
    "            [bx, by, bw, bh] = ann.bbox.xywh\n",
    "            poly = [[bx, by], [bx, by+bh], [bx+bw, by+bh], [bx+bw, by]]\n",
    "            np_poly = np.array(poly).reshape((4,2))\n",
    "            polygons.append(patches.Polygon(np_poly))\n",
    "            color.append(c)\n",
    "            name = ann.oid if id2cat is None else id2cat[ann.oid]\n",
    "            ax.text(bx+1, by-2, name, fontsize=fontsize, color='white', va='bottom',\n",
    "                    bbox=dict(facecolor=c, edgecolor=c, pad=2, alpha=.9))\n",
    "\n",
    "    p = PatchCollection(polygons, facecolor=color, linewidths=0, alpha=0.4)\n",
    "    ax.add_collection(p)\n",
    "    p = PatchCollection(polygons, facecolor='none', edgecolors=color, linewidths=2)\n",
    "    ax.add_collection(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2cat = {o['id']:o['name'] for o in annot_json['categories']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working on RLE??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = random.choice(records)\n",
    "show_record(record, id2cat=id2cat, bbox=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid(partial(show_record, id2cat=id2cat, bbox=False), records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 02_data.core.ipynb.\n",
      "Converted 04_data.annotations.ipynb.\n",
      "Converted 06_transforms.ipynb.\n",
      "Converted 07_data.load.ipynb.\n",
      "Converted 08_models.ipynb.\n",
      "Converted 11_evaluation.coco.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted Untitled1.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
