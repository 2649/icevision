{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp metrics.core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Base-Metric\" data-toc-modified-id=\"Base-Metric-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Base Metric</a></span></li><li><span><a href=\"#COCO-Metric\" data-toc-modified-id=\"COCO-Metric-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>COCO Metric</a></span><ul class=\"toc-item\"><li><span><a href=\"#COCO-conversion\" data-toc-modified-id=\"COCO-conversion-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>COCO conversion</a></span></li><li><span><a href=\"#COCO-metric\" data-toc-modified-id=\"COCO-metric-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>COCO metric</a></span></li></ul></li></ul></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from mantisshrimp.imports import *\n",
    "from mantisshrimp.core import *\n",
    "from mantisshrimp.models import *\n",
    "from mantisshrimp.metrics.coco_eval import CocoEvaluator\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "> Definition of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Metric:\n",
    "    def __init__(self): self._model = None\n",
    "    def step(self, xb, yb, preds): raise NotImplementedError\n",
    "    def end(self, outs): raise NotImplementedError\n",
    "    def register_model(self, model): self._model = model\n",
    "    @property\n",
    "    def model(self):\n",
    "        if notnone(self._model): return self._model\n",
    "        raise RuntimeError('Register a model with `register_model` before using the metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO Metric\n",
    "> Mostly copied from pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def records2coco(records, catmap):\n",
    "    cats = [{'id':i, 'name':o.name} for i,o in catmap.i2o.items()]\n",
    "    annots = defaultdict(list)\n",
    "    iinfos = []\n",
    "    i = 0\n",
    "    for r in tqdm(records):\n",
    "        iinfos.append({\n",
    "            'id': r.iinfo.iid,\n",
    "            'file_name': r.iinfo.fp.name,\n",
    "            'width': r.iinfo.w,\n",
    "            'height': r.iinfo.h,\n",
    "        })\n",
    "        for annot in r.annot: \n",
    "            annots['id'].append(i) # TODO: Careful with ids! when over all dataset\n",
    "            annots['image_id'].append(r.iinfo.iid)\n",
    "            annots['category_id'].append(annot.oid)\n",
    "            annots['bbox'].append(annot.bbox.xywh)\n",
    "            annots['area'].append(annot.bbox.area)\n",
    "            # TODO: for other types of masks\n",
    "            if notnone(annot.seg): annots['segmentation'].extend(annot.seg.to_erle(r.iinfo.h, r.iinfo.w))\n",
    "            annots['iscrowd'].append(annot.iscrowd)\n",
    "            # TODO: Keypoints\n",
    "            i += 1\n",
    "    assert allequal(lmap(len, annots.values())), 'Mismatch lenght of elements'\n",
    "    annots = [{k:v[i] for k,v in annots.items()} for i in range_of(annots['id'])]\n",
    "    return {'images': iinfos, 'annotations': annots, 'categories': cats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def coco_api_from_records(records, catmap):\n",
    "    coco_ds = COCO()\n",
    "    coco_ds.dataset = records2coco(records, catmap)\n",
    "    coco_ds.createIndex()\n",
    "    return coco_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_iou_types(model):\n",
    "    model_without_ddp = model\n",
    "    if isinstance(model, torch.nn.parallel.DistributedDataParallel):\n",
    "        model_without_ddp = model.module\n",
    "    iou_types = [\"bbox\"]\n",
    "    if isinstance(model_without_ddp, MaskRCNNModel):\n",
    "        iou_types.append(\"segm\")\n",
    "    if isinstance(model_without_ddp, torchvision.models.detection.KeypointRCNN):\n",
    "        raise NotImplementedError\n",
    "#         iou_types.append(\"keypoints\")\n",
    "    return iou_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class COCOMetric(Metric):\n",
    "    def __init__(self, records, catmap):\n",
    "        super().__init__()\n",
    "        self._coco_ds = coco_api_from_records(records, catmap)\n",
    "        \n",
    "    def register_model(self, model):\n",
    "        super().register_model(model)\n",
    "        self._create_coco_eval()\n",
    "        \n",
    "    def step(self, xb, yb, preds):\n",
    "        # TODO: Implement batch_to_cpu helper function\n",
    "        preds = [{k:v.to(torch.device('cpu')) for k,v in p.items()} for p in preds]\n",
    "        res = {y[\"image_id\"].item():pred for y,pred in zip(yb, preds)}\n",
    "        self.coco_evaluator.update(res)\n",
    "        \n",
    "    def end(self, outs):\n",
    "        self.coco_evaluator.synchronize_between_processes()\n",
    "        self.coco_evaluator.accumulate()\n",
    "        self.coco_evaluator.summarize()\n",
    "        self._create_coco_eval()\n",
    "        \n",
    "    def _create_coco_eval(self):\n",
    "        self.coco_evaluator = CocoEvaluator(self._coco_ds, _get_iou_types(self.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 02_data.core.ipynb.\n",
      "Converted 04_data.annotations.ipynb.\n",
      "Converted 06_transforms.ipynb.\n",
      "Converted 07_data.load.ipynb.\n",
      "Converted 08_models.ipynb.\n",
      "Converted 11_metrics.core.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted Untitled1.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
